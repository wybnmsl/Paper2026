# Auto-generated by EoH — accepted GLS solver (framework + evolved heuristic)
# (MODIFIED) Adds dataset loader, tqdm progress, and CSV export for TSPAEL64.pkl
# ---------------------------------------------------------------------------------
# Importable usage (unchanged):
#   from 20251018_091112_seq2_export import GLS_SPEC, build_heuristic_module, solve_instance_export, evaluate_dataset
#   heuristic = build_heuristic_module()
#   gap = solve_instance_export(n, opt_cost, dis_matrix, coord,
#                               time_limit=GLS_SPEC.get('stopping', {}).get('time_limit_s', 10.0),
#                               ite_max=1000, perturbation_moves=1)
#
# CLI usage (new):
#   python zTSP/test/20251018_091112_seq2_export.py \
#       --dataset zTSP/TrainingData/TSPAEL64.pkl \
#       --csv zTSP/evaluation/tspael64_export_results.csv \
#       --time_limit 10 --ite_max 1000 --perturbation_moves 1
#   # 选项：
#   #   --limit N        只评 N 个实例（默认全量）
#   #   --no_tqdm        关闭进度条
# ---------------------------------------------------------------------------------

import json
import types
import os
import sys

# ===== Robust import for gls.gls_run =====
_here = os.path.abspath(os.path.dirname(__file__))
_candidates = [
    os.path.abspath(os.path.join(_here, "..")),        # zTSP/
    os.path.abspath(os.path.join(_here, "..", "..")),  # project root (EoH-main)
]
for _p in _candidates:
    if _p not in sys.path:
        sys.path.insert(0, _p)

try:
    from gls.gls_run import solve_instance_with_spec
except Exception:
    try:
        from zTSP.gls.gls_run import solve_instance_with_spec
    except Exception as _e:
        raise ImportError(
            "Cannot import solve_instance_with_spec. Tried 'gls.gls_run' and 'zTSP.gls.gls_run'. "
            "Make sure this script is run inside the project (e.g., from repo root or zTSP/), "
            "or that the project root / zTSP is on PYTHONPATH."
        ) from _e

GLS_SPEC = {
  "init": {
    "method": "nearest_neighbor",
    "start": 0
  },
  "candset": {
    "type": "kNN",
    "k": 100
  },
  "operators": [
    { "name": "two_opt", "strategy": "first" },
    { "name": "relocate", "strategy": "first" }
  ],
  "schedule": { "loop_max": 1000, "max_no_improve": 80 },
  "accept":   { "type": "improve_only", "temp0": 0.0 },
  "perturb":  { "type": "double_bridge", "interval": 80 },
  "guidance": { "where": "mid_ls", "weight": 1.0, "top_k": 5 },
  "stopping": { "time_limit_s": 10.0 }
}

def build_heuristic_module():
    """Build a Python module containing the evolved `update_edge_distance` function."""
    USER_CODE = r'''
def update_edge_distance(edge_distance, local_opt_tour, edge_n_used):
    import numpy as np

    D = np.array(edge_distance, dtype=float, copy=True)
    U = np.array(edge_n_used, dtype=float, copy=True)
    tour = np.asarray(local_opt_tour, dtype=int).copy()

    if D.ndim != 2 or D.shape[0] != D.shape[1]:
        raise ValueError("edge_distance must be a square matrix")
    N = D.shape[0]
    if U.ndim != 2 or U.shape != (N, N):
        raise ValueError("edge_n_used must match shape of edge_distance")

    # Symmetrize and sanitize
    D = 0.5 * (D + D.T)
    U = 0.5 * (U + U.T)
    np.fill_diagonal(D, 0.0)
    np.fill_diagonal(U, 0.0)
    eps = 1e-12

    # Build undirected tour mask
    tour_mask = np.zeros((N, N), dtype=float)
    if tour.size >= 2:
        L = tour.size
        for k in range(L):
            i = int(tour[k]) % N
            j = int(tour[(k + 1) % L]) % N
            if 0 <= i < N and 0 <= j < N:
                tour_mask[i, j] = 1.0
                tour_mask[j, i] = 1.0

    # Usage score in [0,1]
    usage_log = np.log1p(U)
    max_log = float(np.nanmax(usage_log)) if usage_log.size > 0 else 0.0
    if max_log > 0.0:
        usage_score = usage_log / max_log
    else:
        usage_score = np.zeros_like(usage_log)

    # Basic scale/temperature choices
    offdiag = ~np.eye(N, dtype=bool)
    mean_dist = float(np.mean(D[offdiag])) if np.any(offdiag) else float(np.mean(D))
    mean_dist = max(mean_dist, eps)
    beta = 1.0 / (mean_dist + 1e-6)  # inverse-temperature for Boltzmann

    # Convert distances to Boltzmann probabilities p_ij ∝ exp(-beta * D_ij)
    P = np.exp(-beta * D)
    P *= offdiag.astype(float)

    total_P = P.sum()
    if total_P <= 0:
        P = offdiag.astype(float) / max(1, offdiag.sum())
    else:
        P = P / total_P

    # Stagnation score: combine tour membership and high usage
    stagnation = tour_mask * (0.6 + 1.4 * usage_score)  # in [0,~2.0]
    # Exploration reward: prefer rarely used non-tour edges
    exploration = (1.0 - usage_score) * (1.0 - tour_mask)

    # Tunable strengths
    gamma = 3.0    # depress stagnation edges
    delta = 1.2    # boost rarely-used non-tour edges
    mix_with_uniform = 0.08

    depress = np.exp(-gamma * stagnation)
    boost = 1.0 + delta * exploration
    Q = P * depress * boost

    # Add a small amount of uniform mass to avoid zeros
    uniform_mass = offdiag.astype(float) / max(1, offdiag.sum())
    Q = (1.0 - mix_with_uniform) * Q + mix_with_uniform * uniform_mass

    # Small stochastic multiplicative perturbation
    seed = int((np.nansum(U) + np.nansum(D) + np.sum(tour_mask)) % (2**31))
    rng = np.random.default_rng(seed)
    base_sigma = 0.06
    sigma_matrix = base_sigma * (1.0 + 2.0 * stagnation)
    noise = rng.normal(loc=0.0, scale=1.0, size=(N, N))
    mult_noise = np.exp(noise * sigma_matrix)
    Q = Q * mult_noise

    # Ensure off-diagonal positivity and renormalize
    Q *= offdiag.astype(float)
    Q = np.maximum(Q, 1e-16)
    Q = Q / Q.sum()

    # Map back to distances: D' = - (1 / beta') * log(Q_ij)
    beta_prime = beta * 0.95
    D_new = - (1.0 / (beta_prime + 1e-12)) * np.log(Q)
    np.fill_diagonal(D_new, 0.0)

    # Post-scale to preserve mean distance roughly
    if np.any(offdiag):
        mean_new = float(np.mean(D_new[offdiag]))
        scale = mean_dist / (mean_new + 1e-12)
        scale = float(np.clip(scale, 0.5, 2.0))
        D_new = D_new * scale

    D_new = 0.5 * (D_new + D_new.T)
    np.fill_diagonal(D_new, 0.0)
    D_new = np.maximum(D_new, 0.0)

    return D_new
'''
    m = types.ModuleType("heuristic_module")
    exec(USER_CODE, m.__dict__)
    return m

def solve_instance_export(n, opt_cost, dis_matrix, coord,
                          time_limit=10.0, ite_max=1000, perturbation_moves=1):
    """Solve a single instance using the exported heuristic + GLS_SPEC.
    Return value is gap percent (consistent with your main runner)."""
    heuristic = build_heuristic_module()
    return solve_instance_with_spec(
        n, float(opt_cost), dis_matrix, coord,
        time_limit, ite_max, perturbation_moves, heuristic, GLS_SPEC
    )

def evaluate_dataset(coords_list, instances_list, opt_costs,
                     time_limit=10.0, ite_max=1000, perturbation_moves=1):
    """Evaluate a list of instances; returns average gap (percent)."""
    import numpy as _np
    gaps = []
    for i in range(len(instances_list)):
        gap = solve_instance_export(i, float(opt_costs[i]), instances_list[i], coords_list[i],
                                    time_limit, ite_max, perturbation_moves)
        if gap < 0 and abs(gap) < 1e-9:
            gap = 0.0
        gaps.append(float(gap))
    return float(_np.mean(_np.array(gaps, dtype=_np.float64)))

# =========================
# Dataset helpers & CLI
# =========================

def load_tspael64(pkl_path):
    """Load zTSP/TrainingData/TSPAEL64.pkl (dict with lists of arrays)."""
    import pickle
    import numpy as np
    with open(pkl_path, "rb") as f:
        data = pickle.load(f)
    coords = data.get("coordinate")
    dists  = data.get("distance_matrix")
    costs  = data.get("cost")
    if coords is None or dists is None or costs is None:
        raise ValueError("TSPAEL64.pkl missing required keys: coordinate / distance_matrix / cost")
    coords = [np.asarray(c) for c in coords]
    dists  = [np.asarray(D) for D in dists]
    costs  = [float(x) for x in costs]
    if not (len(coords) == len(dists) == len(costs)):
        raise ValueError("coordinate / distance_matrix / cost length mismatch")
    return coords, dists, costs

def evaluate_tspael64_to_csv(pkl_path, csv_out,
                             time_limit=None, ite_max=1000, perturbation_moves=1,
                             limit=None, tqdm_disable=False):
    """Run full-batch evaluation on TSPAEL64.pkl and write a CSV summary."""
    import time as _time
    import numpy as _np
    try:
        import pandas as _pd
    except Exception:
        _pd = None
    from tqdm import tqdm

    coords, dists, costs = load_tspael64(pkl_path)
    n_all = len(dists)
    n = min(n_all, int(limit)) if (limit is not None) else n_all

    if time_limit is None:
        time_limit = float(GLS_SPEC.get("stopping", {}).get("time_limit_s", 10.0))

    rows = []
    it = tqdm(range(n), disable=tqdm_disable, desc="Evaluating TSPAEL64", unit="inst")

    for i in it:
        opt = float(costs[i])
        D   = dists[i]
        C   = coords[i]
        N   = int(D.shape[0]) if hasattr(D, "shape") and D.ndim >= 2 else None

        t0 = _time.time()
        try:
            gap = solve_instance_export(i, opt, D, C, time_limit=time_limit,
                                        ite_max=ite_max, perturbation_moves=perturbation_moves)
            if gap < 0 and abs(gap) < 1e-9:
                gap = 0.0
            err_msg = ""
        except Exception as e:
            gap = float("nan")
            err_msg = str(e)
        dt = _time.time() - t0

        sol_est = opt * (1.0 + (gap/100.0)) if _np.isfinite(gap) else float("nan")

        rows.append({
            "idx": i,
            "N": N,
            "opt_cost": opt,
            "sol_cost_est": sol_est,
            "gap_percent": gap,
            "time_s": dt,
            "time_limit_s": time_limit,
            "loop_max": GLS_SPEC.get("schedule", {}).get("loop_max"),
            "max_no_improve": GLS_SPEC.get("schedule", {}).get("max_no_improve"),
            "k": GLS_SPEC.get("candset", {}).get("k"),
            "top_k": GLS_SPEC.get("guidance", {}).get("top_k"),
            "perturb": GLS_SPEC.get("perturb", {}).get("type"),
            "perturb_interval": GLS_SPEC.get("perturb", {}).get("interval"),
            "error": err_msg,
        })

    # write CSV
    if _pd is not None:
        import os as _os
        _os.makedirs(os.path.dirname(csv_out) or ".", exist_ok=True)
        df = _pd.DataFrame(rows)
        df.to_csv(csv_out, index=False)
    else:
        import csv as _csv
        import os as _os
        _os.makedirs(os.path.dirname(csv_out) or ".", exist_ok=True)
        keys = list(rows[0].keys()) if rows else []
        with open(csv_out, "w", newline="", encoding="utf-8") as f:
            w = _csv.DictWriter(f, fieldnames=keys)
            w.writeheader()
            w.writerows(rows)

    avg_gap = float(_np.nanmean([r["gap_percent"] for r in rows])) if rows else float("nan")
    avg_time = float(_np.nanmean([r["time_s"] for r in rows])) if rows else float("nan")
    print(f"[summary] instances={n}/{n_all} | avg_gap%={avg_gap:.6f} | avg_time_s={avg_time:.3f} | csv -> {csv_out}")

    return rows

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Evaluate accepted GLS export on TSPAEL64.pkl and write CSV (with tqdm).")
    parser.add_argument("--dataset", type=str, default="zTSP/TrainingData/TSPAEL64.pkl",
                        help="Path to TSPAEL64.pkl (default: zTSP/TrainingData/TSPAEL64.pkl)")
    parser.add_argument("--csv", type=str, default="zTSP/evaluation/tspael64_export_results.csv",
                        help="Output CSV path (default: zTSP/evaluation/tspael64_export_results.csv)")
    parser.add_argument("--time_limit", type=float, default=None,
                        help="Override time_limit (sec); default uses GLS_SPEC.stopping.time_limit_s")
    parser.add_argument("--ite_max", type=int, default=1000, help="ite_max passed to solver (default: 1000)")
    parser.add_argument("--perturbation_moves", type=int, default=1, help="perturbation_moves (default: 1)")
    parser.add_argument("--limit", type=int, default=None, help="Evaluate only first N instances (default: all)")
    parser.add_argument("--no_tqdm", action="store_true", help="Disable tqdm progress bar")
    args = parser.parse_args()

    evaluate_tspael64_to_csv(
        pkl_path=args.dataset,
        csv_out=args.csv,
        time_limit=args.time_limit,
        ite_max=args.ite_max,
        perturbation_moves=args.perturbation_moves,
        limit=args.limit,
        tqdm_disable=args.no_tqdm
    )
